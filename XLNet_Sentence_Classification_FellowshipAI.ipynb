{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "XLNet Sentence Classification - FellowshipAI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq2NOE3qH46J"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this Colab notebook, I perform sentiment analysis using XLNET on the Twitter US Airline dataset, and apply the EDA augmentation. I then report the performance metrics (before and after augmentation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "## Install and Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSU7yERLP_66"
      },
      "source": [
        "We'll train a neural network with a GPU provided by Google. \n",
        "\n",
        "Add the GPU by going to the menu and selecting:\n",
        "\n",
        "Edit -> Notebook Settings -> Add accelerator (GPU)\n",
        "\n",
        "Run the following cell to confirm that the GPU is detected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ElsnSNUridI"
      },
      "source": [
        "Next, install transformers for XLNet by Hugging Face. (This library contains interfaces for other pretrained language models like OpenAI's GPT, BERT, and GPT-2.)\n",
        "\n",
        "At the moment, the Hugging Face library seems to be the most widely accepted and powerful pytorch interface for transfer learning models. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1_FWh9JbFaW"
      },
      "source": [
        "#xlnet requires the sentencepiece module\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok002ceNB8E7"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification\n",
        "from transformers import AdamW\n",
        "\n",
        "import sentencepiece\n",
        "\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqG7FzRVFEIv"
      },
      "source": [
        "In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "## Load Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9ZKxKc04Btk"
      },
      "source": [
        "We use the Twitter Airline Sentiment dataset.  It's a set of Tweets labeled as 'positive', 'negative', or 'neutral'. \n",
        "\n",
        "The dataset can be found at the following location: https://www.kaggle.com/crowdflower/twitter-airline-sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOpikSXbsvn-"
      },
      "source": [
        "# Upload the train file from your local drive\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UkeC7SG2krJ"
      },
      "source": [
        "# Read the datafile (in .csv format)\n",
        "df = pd.read_csv('/content/Tweets.csv', converters={'column_name': eval})"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UfxtwQy3axu"
      },
      "source": [
        "# Review the dimensions of the dataframe\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84ILNnnBid0x"
      },
      "source": [
        "# Familiarize yourself with the dataframe by visual inspection\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RH6rM7djwoG"
      },
      "source": [
        "# Format Dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp0ONGZqO0or"
      },
      "source": [
        "# Drop columns not needed for the analysis\n",
        "df = df.drop('tweet_id', 1)\n",
        "df = df.drop('airline_sentiment_confidence', 1)\n",
        "df = df.drop('negativereason', 1)\n",
        "df = df.drop('negativereason_confidence', 1)\n",
        "df = df.drop('airline', 1)\n",
        "df = df.drop('airline_sentiment_gold', 1)\n",
        "df = df.drop('retweet_count', 1)\n",
        "df = df.drop('tweet_coord', 1)\n",
        "df = df.drop('tweet_created', 1)\n",
        "df = df.drop('tweet_location', 1)\n",
        "df = df.drop('user_timezone', 1)\n",
        "df = df.drop('name', 1)\n",
        "df = df.drop('negativereason_gold', 1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJXHnaM9dHiu"
      },
      "source": [
        "# Drop columns with empty cells\n",
        "df. dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqvWHQWLVusR"
      },
      "source": [
        "# create a dictionary file  \n",
        "sentiment = {'neutral': 0, 'positive': 1,'negative': 2} \n",
        "  \n",
        "# Traverse through dataframe  \n",
        "# Assign values where key matches \n",
        "df.airline_sentiment = [sentiment[item] for item in df.airline_sentiment] "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7HFYUOvVu6L"
      },
      "source": [
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcbx9FGAqTyI"
      },
      "source": [
        "# Format the 'airline_sentiment' column as a categorical variable\n",
        "df['airline_sentiment'] = df.airline_sentiment.astype('category')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahdsYEmKaw_w"
      },
      "source": [
        "df['airline_sentiment'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N34tL6C_5zRR"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmgblCPVLzLd"
      },
      "source": [
        "# Data Augmentation (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Od2vRUUL5EJ"
      },
      "source": [
        "# Import EDA\n",
        "try:\n",
        "    from textaugment import EDA\n",
        "except ModuleNotFoundError:\n",
        "    !pip install textaugment\n",
        "    from textaugment import EDA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e4JTF-SOr3J"
      },
      "source": [
        "# Import NLTK and download modules needed for EDA\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKjDzJAANqqD"
      },
      "source": [
        "t = EDA(random_state=1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF5XAqFzOzoK"
      },
      "source": [
        "# Synonym Replacement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a14KuRiFR_kq"
      },
      "source": [
        "# Visually inspect the first row of the 'text' column for verification\n",
        "df['text'][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ajsQWdUOwnB"
      },
      "source": [
        "# Loop for EDA to perform synonym replacement\n",
        "for row in range(0, len(df)):\n",
        "    df['text'][row] = t.synonym_replacement(df['text'][row])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5_c7-lZPjgv"
      },
      "source": [
        "# Visually inspect the first row of the 'text' column to verify a word has been \n",
        "# replaced by its synonym. \n",
        "df['text'][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bILjVgtGVqiH"
      },
      "source": [
        "# Random Insertion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-NtUK6kWDZu"
      },
      "source": [
        "# Loop for EDA to perform random insertion \n",
        "for row in range(0, len(df)):\n",
        "    df['text'][row] = t.random_insertion(df['text'][row])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYm2tiTMdUz3"
      },
      "source": [
        "# Visually inspect the first row of the 'text' column to verify \n",
        "# a word has been randomly inserted.  \n",
        "df['text'][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cln5zynWVtTN"
      },
      "source": [
        "# Random Swap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ-1rwOpWEsG"
      },
      "source": [
        "# Loop for EDA to perform random swap\n",
        "for row in range(0, len(df)):\n",
        "    df['text'][row] = t.random_swap(df['text'][row])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNUlhg1KkJat"
      },
      "source": [
        "# Visually inspect the first row of the 'text' column to verify \n",
        "# a word has been randomly swapped.  \n",
        "df['text'][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G63OGwV_Vtt0"
      },
      "source": [
        "# Random Deletion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRZcUJGCWFpH"
      },
      "source": [
        "# Loop for EDA to perform random deletion\n",
        "for row in range(0, len(df)):\n",
        "    df['text'][row] = t.random_deletion(df['text'][row])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-2tLtlpkNVV"
      },
      "source": [
        "# Visually inspect the first row of the 'text' column to verify \n",
        "# a word has been randomly deleted.  \n",
        "df['text'][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3bwVPwGjl5k"
      },
      "source": [
        "# Create Holdout Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hla0J4PqQTUI"
      },
      "source": [
        "import random\n",
        "# Create new colunm named 'carve_assignment'\n",
        "df['carve_assignment'] = \"\"\n",
        "\n",
        "# Loop over rows in 'carve_assignment'\n",
        "# Assign a random number between 0 and 1 to the 'carve_assignment' column\n",
        "for row in range(0, len(df)):\n",
        "    df['carve_assignment'][row] = random.random()\n",
        "\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSLH1rwRiGYo"
      },
      "source": [
        "# Assign rows from column 'carve_assignment' with value equal or greater than 0.8 to holdout dataset\n",
        "holdout = df[df['carve_assignment'] >= 0.8]\n",
        "\n",
        "# Assign rows from column 'carve_assignment' with value less than 0.8 to 'df' dataframe\n",
        "df = df[df['carve_assignment'] < 0.8]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR0I14ON86R1"
      },
      "source": [
        "# Verify proportions of data in each dataset\n",
        "print(df.shape)\n",
        "print(holdout.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rZorwjJMiAN"
      },
      "source": [
        "# Drop column named 'carve_assignment' from both dataframes\n",
        "df = df.drop('carve_assignment', 1)\n",
        "holdout = holdout.drop('carve_assignment', 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J13Czefy5ruw"
      },
      "source": [
        "# Save 'holdout' dataset to CSV for later analysis\n",
        "holdout.to_csv('holdout.csv', index=False)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF1I8Jf3mxmA"
      },
      "source": [
        "# Delete 'holdout' dataset and release from memory\n",
        "del holdout"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAlrTEBf9L6q"
      },
      "source": [
        "# Format Sentences for XLNet "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sPDL2qOTxSU"
      },
      "source": [
        "# Create sentence and label lists\n",
        "sentences = df.text.values"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD4eTl03TmUq"
      },
      "source": [
        "We need to add special tokens (\"[SEP]\" and \"[CLS]\") at the beginning and end of each sentence for XLNet to work properly. \n",
        "\n",
        "For XLNet the token pattern looks like this:\n",
        "\n",
        "    Sentence_A + [SEP] + Sentence_B + [SEP] + [CLS]\n",
        "    \n",
        "For single sentence inputs (such as we have here), we just need to add [SEP] and [CLS] to the end:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuE5BqICAne2"
      },
      "source": [
        "sentences = [sentence + \" [SEP] [CLS]\" for sentence in sentences]\n",
        "labels = df.airline_sentiment"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s29PFdz3nuJZ"
      },
      "source": [
        "# Delete the 'df' dataframe and release from memory; it is no longer needed\n",
        "# The subsequent analysis will be conducted on the 'sentences' and 'labels' lists\n",
        "# A separate dataframe named 'df' will be created later from the 'holdout' dataset\n",
        "del df"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "## Tokenize Sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTREubVNFiz4"
      },
      "source": [
        "Next, import the XLNet tokenizer, and convert the text into tokens that correspond to XLNet's vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A"
      },
      "source": [
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "print (\"Tokenize the first sentence:\")\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87_kXUeT2-br"
      },
      "source": [
        "XLNet requires specifically formatted inputs. For each tokenized input sentence, we need to create:\n",
        "\n",
        "- **input ids**: a sequence of integers identifying each input token to its index number in the XLNet tokenizer vocabulary\n",
        "- **segment mask**: (optional) a sequence of 1s and 0s used to identify whether the input is one sentence or two sentences long. For one sentence inputs, this is simply a sequence of 0s. For two sentence inputs, there is a 0 for each token of the first sentence, followed by a 1 for each token of the second sentence\n",
        "- **attention mask**: (optional) a sequence of 1s and 0s, with 1s for all input tokens and 0s for all padding tokens (we'll detail this in the next paragraph)\n",
        "- **labels**: a single value of 0, 1, or 2 to characterize the sentiment of the sentence (here, Tweet).  In our task 0 means 'neutral', 1 means 'positive', and 2 means 'negative'. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xytsw1oIfnX0"
      },
      "source": [
        "Although we can have variable length input sentences, XLNet requires the input arrays to be the same size. We address this by choosing a maximum sentence length, and then padding and truncating the inputs until each input sequence is the same length. \n",
        "\n",
        "To \"pad\" inputs means that if a sentence is shorter than the maximum sentence length, we add 0s to the end of the sequence until it is the maximum sentence length. \n",
        "\n",
        "If a sentence is longer than the maximum sentence length, we truncate the end of the sequence, discarding anything that does not fit into the maximum sentence length.\n",
        "\n",
        "We pad and truncate our sequences so that they are all of length MAX_LEN (\"post\" indicates that we want to pad and truncate at the end of the sequence, as opposed to the beginning) `pad_sequences` is a utility function from Keras. It handles the truncating and padding of Python lists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp9BPRd1tMIo"
      },
      "source": [
        "# Set the maximum sequence length.  This value leaves plenty of 'room'. \n",
        "MAX_LEN = 140"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFhowDMohU4H"
      },
      "source": [
        "# Use the XLNet tokenizer to convert the tokens to their index numbers in the XLNet vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDs-MYtYH8sL"
      },
      "source": [
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhGulL1pExCT"
      },
      "source": [
        "Create the attention masks "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDoC24LeEv3N"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFbE-UHvsb7-"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.2, stratify=labels)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.2)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpyzjzbxH4MP"
      },
      "source": [
        "# Identify Data Types\n",
        "print(type(train_inputs))\n",
        "print(type(train_labels))\n",
        "print(type(train_masks))\n",
        "\n",
        "print(type(validation_inputs))\n",
        "print(type(validation_labels))\n",
        "print(type(validation_masks))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3VE982WH03C"
      },
      "source": [
        "# Convert Series to numpy array \n",
        "train_labels = np.asarray(train_labels)\n",
        "validation_labels = np.asarray(validation_labels)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmEzmX9mE3hi"
      },
      "source": [
        "# Convert list to numpy array\n",
        "train_masks = np.asarray(train_masks)\n",
        "validation_masks = np.asarray(validation_masks)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRqu-thtDUzC"
      },
      "source": [
        "# Verify Data Types\n",
        "print(type(train_inputs))\n",
        "print(type(train_labels))\n",
        "print(type(train_masks))\n",
        "\n",
        "print(type(validation_inputs))\n",
        "print(type(validation_labels))\n",
        "print(type(validation_masks))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAASCakWGJS2"
      },
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "\n",
        "train_inputs = torch.from_numpy(train_inputs)\n",
        "validation_inputs = torch.from_numpy(validation_inputs)\n",
        "\n",
        "train_labels = torch.from_numpy(train_labels)\n",
        "validation_labels = torch.from_numpy(validation_labels)\n",
        "\n",
        "train_masks = torch.from_numpy(train_masks)\n",
        "validation_masks = torch.from_numpy(validation_masks)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO5gaypmPZC5"
      },
      "source": [
        "# Verify the data type (all should be torch tensors)\n",
        "print(train_inputs.size())\n",
        "print(validation_inputs.size())\n",
        "\n",
        "print(train_labels.size())\n",
        "print(validation_labels.size())\n",
        "\n",
        "print(train_masks.size())\n",
        "print(validation_masks.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-"
      },
      "source": [
        "# Select a batch size for training. For fine-tuning with XLNet, the authors recommend a batch size of 32, 48, or 128. We will use 32 here to avoid memory issues.\n",
        "batch_size = 32\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNl8khAhPYju"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwQ7JcuJQZ0o"
      },
      "source": [
        "Now that the input data is properly formatted, we fine tune the XLNet model. \n",
        "\n",
        "For this task, we first modify the pre-trained model to give outputs for classification, and then continue training the model on our dataset until the entire model, end-to-end, is well-suited for our task.   \n",
        "\n",
        "Load [XLNetForSequenceClassification](https://github.com/huggingface/pytorch-transformers/blob/master/pytorch_transformers/modeling_xlnet.py#L1076). This is the baseline XLNet model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the pre-trained XLNet model and the additional untrained classification layer is trained on our specific task. \n",
        "\n",
        "### The Fine-Tuning Process\n",
        "\n",
        "Because the pre-trained model layers already encode a lot of information about the language, training the classifier is relatively inexpensive. Rather than training every layer in a large model from scratch, it's as if we have already trained the bottom layers 95% of where they need to be, and only really need to train the top layer, with a bit of tweaking in the lower levels to accomodate our task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnQW9E-bBCRt"
      },
      "source": [
        "There are a few different pre-trained XLNet models available. \"xlnet-base-cased\" means the version that has both upper and lowercase letters (\"cased\") and is the smaller version of the two (\"base\" vs \"large\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB"
      },
      "source": [
        "# Load XLNEtForSequenceClassification, the pretrained XLNet model with a single linear classification layer on top. \n",
        "\n",
        "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=3)\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-VEBobKwHk"
      },
      "source": [
        "Now that the model is loaded, we need to grab the training hyperparameters from within the stored model.\n",
        "\n",
        "For the purpose of fine-tuning, the authors recommend the following hyperparameters (broken down by which NLP dataset they are applied to):\n",
        "\n",
        "![alt text](https://i.imgur.com/AhirErN.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxSMw0FrptiL"
      },
      "source": [
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "# This variable contains all of the hyperparemeter information our training loop needs\n",
        "optimizer = AdamW(optimizer_grouped_parameters,\n",
        "                     lr=2e-5)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QXZhFb4LnV5"
      },
      "source": [
        "Below is our training loop. For each pass in our loop we have a training phase and a validation phase. At each pass we need to:\n",
        "\n",
        "Training loop:\n",
        "- Tell the model to compute gradients by setting the model in train mode\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Clear out the gradients calculated in the previous pass. In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out\n",
        "- Forward pass (feed input data through the network)\n",
        "- Backward pass (backpropagation)\n",
        "- Tell the network to update parameters with optimizer.step()\n",
        "- Track variables for monitoring progress\n",
        "\n",
        "Evalution loop:\n",
        "- Tell the model not to compute gradients by setting th emodel in evaluation mode\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Forward pass (feed input data through the network)\n",
        "- Compute loss on our validation data and track variables for monitoring progress\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_"
      },
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  \n",
        "  \n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "    loss = outputs[0]\n",
        "    logits = outputs[1]\n",
        "    train_loss_set.append(loss.item())    \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    \n",
        "    \n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "      logits = output[0]\n",
        "    \n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyRa-5CcHv_g"
      },
      "source": [
        "## Training Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-G03mmwH3aI"
      },
      "source": [
        "Plot and review training loss over all batches:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5"
      },
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_loss_set)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "##Predict and Evaluate on Holdout Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DosV94BYIYxg"
      },
      "source": [
        "Now we'll load the holdout dataset and prepare inputs just as we did with the training set. Then we'll evaluate predictions using [Matthew's correlation coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html).  This is the metric used by the wider NLP community to evaluate performance on CoLA. With this metric, +1 is the best score, and -1 is the worst score. This way, we can see how well we perform against the state of the art models for this specific task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyBuXVGoOLQf"
      },
      "source": [
        "# Upload the test file from your local drive\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXXdPBSHvG80"
      },
      "source": [
        "# Or, upload the test from directly\n",
        "df = pd.read_csv(\"/content/holdout.csv\")"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh"
      },
      "source": [
        "# Create sentence and label lists\n",
        "sentences = df.text.values\n",
        "\n",
        "# We need to add special tokens at the beginning and end of each sentence for XLNet to work properly\n",
        "sentences = [sentence + \" [SEP] [CLS]\" for sentence in sentences]\n",
        "labels = df.airline_sentiment\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "\n",
        "MAX_LEN = 140\n",
        "\n",
        "# Use the XLNet tokenizer to convert the tokens to their index numbers in the XLNet vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) "
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w_UHq6Yy5Lz"
      },
      "source": [
        "# Review data type of input variables\n",
        "print(type(input_ids))\n",
        "print(type(attention_masks))\n",
        "print(type(labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xW48JHuzzG4"
      },
      "source": [
        "# Convert list to numpy array \n",
        "attention_masks = np.asarray(attention_masks)\n",
        "\n",
        "# Convert Series to numpy array \n",
        "labels = np.asarray(labels)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86FkB8xq0Pp-"
      },
      "source": [
        "# Review data type of input variables (they should be numpy arrays at this point)\n",
        "print(type(input_ids))\n",
        "print(type(attention_masks))\n",
        "print(type(labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mLjoxszylch"
      },
      "source": [
        "prediction_inputs = torch.from_numpy(input_ids)\n",
        "prediction_masks = torch.from_numpy(attention_masks)\n",
        "prediction_labels = torch.from_numpy(labels)\n",
        "  \n",
        "batch_size = 32  \n",
        "\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n",
        "  with torch.no_grad():\n",
        "    # Forward pass, calculate logit predictions\n",
        "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRaZQ4XC7kLs"
      },
      "source": [
        "# Import and evaluate each test batch using Matthew's correlation coefficient\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "matthews_set = []\n",
        "\n",
        "for i in range(len(true_labels)):\n",
        "  matthews = matthews_corrcoef(true_labels[i],\n",
        "                 np.argmax(predictions[i], axis=1).flatten())\n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUM0UA1qJaVB"
      },
      "source": [
        "The final score will be based on the entire test set, but let's take a look at the scores on the individual batches to get a sense of the variability in the metric between batches.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xytAr_C48wnu"
      },
      "source": [
        "matthews_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCYZa1lQ8Jn8"
      },
      "source": [
        "# Flatten the predictions and true values for aggregate Matthew's evaluation on the whole dataset\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-4EBZ8D8VsZ"
      },
      "source": [
        "# Print the Matthews Correleation Coefficient\n",
        "matthews_corrcoef(flat_true_labels, flat_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXx0jPc4HUfZ"
      },
      "source": [
        "At this point, we've fine-tuned XLNet.\n",
        "\n",
        "To improve this score, we can experiment with hyperparameter tuning (adjusting the learning rate, epochs, batch size, optimizer properties, etc.). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfjYoa6WmkN6"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlQG7qgkmf4n"
      },
      "source": [
        "This notebook shows how to train an XLNet model with the huggingface pytorch interface."
      ]
    }
  ]
}